# LLM Providers Configuration
# Defines connection details for each LLM provider

providers:
  openai:
    endpoint: https://api.openai.com/v1
    api_key_env: OPENAI_API_KEY
    max_context: 128000
    supports_streaming: true
    supports_tools: true

  anthropic:
    endpoint: https://api.anthropic.com
    api_key_env: ANTHROPIC_API_KEY
    max_context: 200000
    supports_streaming: true
    supports_tools: true

  gemini:
    endpoint: https://generativelanguage.googleapis.com
    api_key_env: GEMINI_API_KEY
    max_context: 1000000
    supports_streaming: true
    supports_tools: true

  ollama:
    endpoint: http://localhost:11434
    api_key_env: null  # Ollama doesn't require API key
    max_context: 8192
    supports_streaming: true
    supports_tools: false

  deepseek:
    endpoint: https://api.deepseek.com/v1
    api_key_env: DEEPSEEK_API_KEY
    max_context: 64000
    supports_streaming: true
    supports_tools: true

  qwen:
    endpoint: https://dashscope.aliyuncs.com/api/v1
    api_key_env: QWEN_API_KEY
    max_context: 32000
    supports_streaming: true
    supports_tools: true

  grok:
    endpoint: https://api.x.ai/v1
    api_key_env: GROK_API_KEY
    max_context: 131072
    supports_streaming: true
    supports_tools: true
