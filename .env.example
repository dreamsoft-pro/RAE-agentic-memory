# RAE Memory API - Environment Configuration Example
# Copy this file to .env and update with your values
# Note: Do not use quotes around values in .env files

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
POSTGRES_HOST=localhost
POSTGRES_DB=rae_memory
POSTGRES_USER=rae_user
POSTGRES_PASSWORD=change_this_password

# =============================================================================
# VECTOR STORE CONFIGURATION
# =============================================================================
RAE_VECTOR_BACKEND=qdrant  # Options: qdrant, pgvector
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Optional: Path to local ONNX embedding model (for air-gapped deployments)
# ONNX_EMBEDDER_PATH=/path/to/model.onnx

# =============================================================================
# REDIS & CELERY CONFIGURATION
# =============================================================================
REDIS_URL=redis://localhost:6379/0
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# =============================================================================
# LLM BACKEND CONFIGURATION
# =============================================================================

# LLM Provider Selection
RAE_LLM_BACKEND=openai  # Options: openai, anthropic, gemini, ollama

# Default Model
RAE_LLM_MODEL_DEFAULT=gpt-4o-mini

# Specialized Models (optional overrides)
EXTRACTION_MODEL=gpt-4o-mini  # For knowledge graph extraction
SYNTHESIS_MODEL=gpt-4o  # For context synthesis and reflections

# Override all models (optional)
# LLM_MODEL=gpt-4o

# --- OpenAI Configuration ---
OPENAI_API_KEY=your-openai-api-key

# --- Anthropic Configuration ---
# ANTHROPIC_API_KEY=your-anthropic-key

# --- Google Gemini Configuration ---
# GEMINI_API_KEY=your-gemini-api-key

# --- Ollama Configuration ---
OLLAMA_API_URL=http://localhost:11434

# --- Other Providers (uncomment to use) ---
# MISTRAL_API_KEY=your-mistral-key
# DEEPSEEK_API_KEY=your-deepseek-key
# DASHSCOPE_API_KEY=your-qwen-key

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# Multi-Tenancy
TENANCY_ENABLED=true  # Always true in production

# OAuth2 / JWT Authentication
OAUTH_ENABLED=true
OAUTH_DOMAIN=your-tenant.auth0.com
OAUTH_AUDIENCE=https://api.yourcompany.com

# API Key Authentication
ENABLE_API_KEY_AUTH=false  # Set to true for service-to-service auth
API_KEY=change_this_api_key_in_production

# JWT Authentication
ENABLE_JWT_AUTH=false  # Set to true when using OAuth2/OIDC
SECRET_KEY=change-this-secret-key-in-production-use-openssl-rand-hex-32

# Rate Limiting
ENABLE_RATE_LIMITING=false  # Set to true in production
RATE_LIMIT_REQUESTS=100  # Max requests per window
RATE_LIMIT_WINDOW=60  # Time window in seconds

# CORS Configuration
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:8501"]

# =============================================================================
# MICROSERVICES CONFIGURATION
# =============================================================================
RERANKER_API_URL=http://localhost:8001
MEMORY_API_URL=http://localhost:8000

# =============================================================================
# MEMORY LIFECYCLE CONFIGURATION
# =============================================================================

# Memory Retention
MEMORY_RETENTION_DAYS=30  # Days to keep episodic memories (0 to disable)

# Memory Decay & Importance Scoring
MEMORY_DECAY_RATE=0.01  # Base decay rate per day (0.01 = 1% per day)
MEMORY_DECAY_ENABLED=true
MEMORY_DECAY_CONSIDER_ACCESS=true  # Use last_accessed_at for decay calculation

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
LOG_LEVEL=WARNING  # For external libraries: DEBUG, INFO, WARNING, ERROR, CRITICAL
RAE_APP_LOG_LEVEL=INFO  # For RAE application: DEBUG, INFO, WARNING, ERROR, CRITICAL

# =============================================================================
# RAE LITE PROFILE (docker-compose.lite.yml)
# =============================================================================
# Minimal deployment with reduced resource requirements (4 GB RAM, 2 CPU)
#
# ML_SERVICE_ENABLED=false       # Disable heavy ML operations
# RERANKER_ENABLED=false         # Disable re-ranking service
# CELERY_ENABLED=false           # Disable async workers
#
# Perfect for: Development, testing, small teams (1-10 users)
# See: docs/deployment/rae-lite-profile.md

# =============================================================================
# NOTES
# =============================================================================
#
# For Development (RAE Lite - Minimal Resources):
#   - Use: docker-compose -f docker-compose.lite.yml up -d
#   - Set ML_SERVICE_ENABLED=false, RERANKER_ENABLED=false, CELERY_ENABLED=false
#   - Use ollama backend: RAE_LLM_BACKEND=ollama
#   - Set RAE_APP_LOG_LEVEL=DEBUG for detailed logs
#
# For Development (Full Stack):
#   - Use: docker-compose up -d
#   - Set OAUTH_ENABLED=false
#   - Use ollama backend: RAE_LLM_BACKEND=ollama
#   - Set RAE_APP_LOG_LEVEL=DEBUG for detailed logs
#
# For Production:
#   - Always use strong, unique passwords
#   - Store secrets in secret management systems (AWS Secrets Manager, Azure Key Vault, etc.)
#   - Enable authentication: OAUTH_ENABLED=true or ENABLE_API_KEY_AUTH=true
#   - Enable rate limiting: ENABLE_RATE_LIMITING=true
#   - Limit CORS to production domains
#   - Use LOG_LEVEL=ERROR and RAE_APP_LOG_LEVEL=INFO
#
# For Docker Compose:
#   - Replace localhost with service names (e.g., postgres, redis, qdrant)
#   - Example: POSTGRES_HOST=postgres, REDIS_URL=redis://redis:6379/0
#
# See docs/configuration.md for complete documentation
#
