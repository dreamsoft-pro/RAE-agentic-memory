# Example Behavior Scenario - CLI Statistics Calculation
# This file demonstrates how to define a behavior scenario for CLI/batch jobs

id: cli-calc-stats-v1
project_id: my-legacy-batch
category: cli
name: Calculate Daily Statistics
description: |
  Test statistics calculation CLI command that processes daily data
  and generates summary report. Verifies that command executes successfully,
  processes all records, and outputs valid statistics.

environment: legacy
tags:
  - cli
  - batch
  - statistics
  - daily-job
  - critical

# Input: CLI command specification
input:
  cli_command:
    command: python
    args:
      - scripts/calculate_stats.py
      - --date
      - "2025-11-26"
      - --output
      - /tmp/stats_output.json
      - --config
      - config/production.yml
      - --verbose

    # Environment variables for the command
    env:
      PYTHONPATH: /app/src
      DATABASE_URL: postgresql://user:pass@localhost/prod_db
      LOG_LEVEL: INFO
      STATS_CALCULATION_MODE: full
      ENABLE_CACHE: "true"

  # Context: additional execution context
  context:
    working_directory: /app
    timeout_seconds: 300  # 5 minutes
    capture_stdout: true
    capture_stderr: true
    expected_exit_code: 0

# Success criteria: multi-layered checks
success_criteria:
  # HTTP checks (not applicable for CLI)
  http: null

  # DOM checks (not applicable for CLI)
  dom: null

  # Log checks (stdout/stderr and application logs)
  logs:
    # Patterns that MUST NOT appear in output
    forbidden_patterns:
      - "ERROR"
      - "CRITICAL"
      - "Exception"
      - "Traceback"
      - "FAILED"
      - "Database connection failed"
      - "Permission denied"
      - "File not found"
      - "Out of memory"
      - "Killed"  # Process killed by OOM killer
      - "Segmentation fault"
      - "AssertionError"

    # Patterns that SHOULD appear in output
    required_patterns:
      - "Statistics calculation started"
      - "Processing records"
      - "Statistics calculation completed successfully"
      - "Total records processed:"
      - "Output saved to"
      # Optional specific patterns:
      # - "Cache hit rate:"
      # - "Average processing time:"

  # Custom rules (evaluated by Feniks/RAE - advanced)
  custom_rules:
    - "exit_code == 0"  # Must exit successfully
    - "execution_time < 300s"  # Under 5 minutes
    - "output_file_exists"  # Output file was created
    - "output_file_valid_json"  # Output is valid JSON
    - "output_contains_expected_keys"  # Has required fields
    - "no_zombie_processes"  # No leftover processes
    - "memory_usage < 2GB"  # Reasonable memory usage
    - "records_processed > 0"  # Actually processed data

# Expected output file structure (for validation)
expected_output_structure:
  type: json
  schema:
    required_keys:
      - date
      - total_records
      - total_amount
      - average_amount
      - statistics
      - processing_time_seconds
      - generated_at

    statistics_keys:
      - count
      - sum
      - mean
      - median
      - std_dev
      - min
      - max
      - percentile_95
      - percentile_99

# Performance expectations
performance:
  max_execution_time_seconds: 300
  max_memory_mb: 2048
  max_cpu_percent: 80
  expected_records_per_second: 1000

# Metadata
created_at: 2025-11-26T20:00:00Z
created_by: batch-admin
