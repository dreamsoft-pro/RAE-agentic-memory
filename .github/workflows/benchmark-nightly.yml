name: Benchmark Nightly

on:
  schedule:
    # Run every night at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:  # Allow manual trigger
    inputs:
      benchmarks:
        description: 'Benchmarks to run (comma-separated)'
        required: false
        default: 'academic_extended,industrial_small'

jobs:
  benchmark-extended:
    name: Extended Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 15

    services:
      postgres:
        image: ankane/pgvector:latest
        env:
          POSTGRES_USER: rae_user
          POSTGRES_PASSWORD: rae_password
          POSTGRES_DB: rae_memory
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Setup database
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_USER: rae_user
          POSTGRES_PASSWORD: rae_password
          POSTGRES_DB: rae_memory
          PGPASSWORD: rae_password
        run: |
          python -c "import asyncpg; import asyncio; asyncio.run(asyncpg.connect('postgresql://rae_user:rae_password@localhost:5432/rae_memory'))"
          echo "âœ… Database connection successful"
          # Run DDL scripts to create base tables
          for sql_file in infra/postgres/ddl/*.sql; do
            echo "Running $sql_file..."
            psql -h localhost -U rae_user -d rae_memory -f "$sql_file"
          done
          echo "âœ… Base schema created"
          # Run migrations
          alembic upgrade head
          echo "âœ… Database migrations complete"

      - name: Run academic_extended benchmark
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_USER: rae_user
          POSTGRES_PASSWORD: rae_password
          POSTGRES_DB: rae_memory
        run: |
          python benchmarking/scripts/run_benchmark.py --set academic_extended.yaml
          echo "âœ… Extended benchmark complete"

      - name: Archive benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-extended-results
          path: benchmarking/results/academic_extended_*.json
          retention-days: 30

  benchmark-industrial:
    name: Industrial Benchmark
    runs-on: ubuntu-latest
    timeout-minutes: 20

    services:
      postgres:
        image: ankane/pgvector:latest
        env:
          POSTGRES_USER: rae_user
          POSTGRES_PASSWORD: rae_password
          POSTGRES_DB: rae_memory
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Setup database
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_USER: rae_user
          POSTGRES_PASSWORD: rae_password
          POSTGRES_DB: rae_memory
          PGPASSWORD: rae_password
        run: |
          python -c "import asyncpg; import asyncio; asyncio.run(asyncpg.connect('postgresql://rae_user:rae_password@localhost:5432/rae_memory'))"
          echo "âœ… Database connection successful"
          # Run DDL scripts to create base tables
          for sql_file in infra/postgres/ddl/*.sql; do
            echo "Running $sql_file..."
            psql -h localhost -U rae_user -d rae_memory -f "$sql_file"
          done
          echo "âœ… Base schema created"
          # Run migrations
          alembic upgrade head
          echo "âœ… Database migrations complete"

      - name: Run industrial_small benchmark
        env:
          POSTGRES_HOST: localhost
          POSTGRES_PORT: 5432
          POSTGRES_USER: rae_user
          POSTGRES_PASSWORD: rae_password
          POSTGRES_DB: rae_memory
        run: |
          python benchmarking/scripts/run_benchmark.py --set industrial_small.yaml
          echo "âœ… Industrial benchmark complete"

      - name: Archive benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-industrial-results
          path: benchmarking/results/industrial_small_*.json
          retention-days: 30

  analyze-results:
    name: Analyze & Report
    runs-on: ubuntu-latest
    needs: [benchmark-extended, benchmark-industrial]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: benchmarking/results/

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml numpy

      - name: Check for regressions
        run: |
          echo "ðŸ“Š Analyzing benchmark results..."

          # Compare against reference metrics
          python3 << 'EOF'
          import json
          import glob
          from pathlib import Path

          reference_file = Path('benchmarking/results/metrics_reference.json')
          with open(reference_file) as f:
              reference = json.load(f)

          # Find latest results
          extended_results = sorted(glob.glob('benchmarking/results/**/academic_extended_*.json', recursive=True))
          industrial_results = sorted(glob.glob('benchmarking/results/**/industrial_small_*.json', recursive=True))

          regressions = []

          if extended_results:
              with open(extended_results[-1]) as f:
                  results = json.load(f)
                  mrr = results['metrics']['mrr']
                  target = reference['benchmarks']['academic_extended']['target_metrics']['quality']['mrr']['min']
                  if mrr < target:
                      regressions.append(f"academic_extended: MRR {mrr:.4f} < target {target}")

          if industrial_results:
              with open(industrial_results[-1]) as f:
                  results = json.load(f)
                  mrr = results['metrics']['mrr']
                  target = reference['benchmarks']['industrial_small']['target_metrics']['quality']['mrr']['min']
                  if mrr < target:
                      regressions.append(f"industrial_small: MRR {mrr:.4f} < target {target}")

          if regressions:
              print("âŒ REGRESSIONS DETECTED:")
              for r in regressions:
                  print(f"  - {r}")
              exit(1)
          else:
              print("âœ… All benchmarks meet quality targets")
          EOF

      - name: Generate summary report
        run: |
          echo "# Nightly Benchmark Report" > benchmark_summary.md
          echo "" >> benchmark_summary.md
          echo "**Date:** $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> benchmark_summary.md
          echo "" >> benchmark_summary.md
          echo "## Results" >> benchmark_summary.md
          echo "" >> benchmark_summary.md

          # Parse results and add to summary
          python3 << 'EOF'
          import json
          import glob

          extended_results = sorted(glob.glob('benchmarking/results/**/academic_extended_*.json', recursive=True))
          industrial_results = sorted(glob.glob('benchmarking/results/**/industrial_small_*.json', recursive=True))

          print("### Academic Extended")
          if extended_results:
              with open(extended_results[-1]) as f:
                  results = json.load(f)
                  print(f"- MRR: {results['metrics']['mrr']:.4f}")
                  print(f"- Hit Rate @5: {results['metrics']['hit_rate']['@5']:.4f}")
                  print(f"- Avg Latency: {results['metrics']['performance']['avg_query_time_ms']:.2f}ms")

          print("\n### Industrial Small")
          if industrial_results:
              with open(industrial_results[-1]) as f:
                  results = json.load(f)
                  print(f"- MRR: {results['metrics']['mrr']:.4f}")
                  print(f"- Hit Rate @5: {results['metrics']['hit_rate']['@5']:.4f}")
                  print(f"- Avg Latency: {results['metrics']['performance']['avg_query_time_ms']:.2f}ms")
          EOF

          echo "âœ… Summary report generated"

      - name: Upload summary
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-summary
          path: benchmark_summary.md
          retention-days: 90
