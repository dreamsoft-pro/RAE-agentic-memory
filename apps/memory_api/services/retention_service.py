"""
Data Retention Service - ISO/IEC 42001 & GDPR Compliance

Manages data lifecycle, retention policies, and right-to-be-forgotten requests.

Key features:
- Per-tenant retention policies (configurable days per data class)
- GDPR-compliant cascade deletion (all related data)
- Audit trail for all deletion operations
- Soft delete with grace period before hard delete
- Data minimization (automatic cleanup of outdated data)
- Retention exceptions for critical data (e.g., legal hold)

ISO/IEC 42001 alignment:
- Section 6: Risk management (RISK-002: Brak kontroli retencji)
- Section 7: Data governance and privacy
- GDPR Article 17: Right to erasure ("right to be forgotten")
- GDPR Article 5: Data minimization and storage limitation
"""

import logging
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Dict, List, Optional
from uuid import UUID

import asyncpg
from pydantic import BaseModel, Field

from apps.memory_api.utils.datetime_utils import utc_now

logger = logging.getLogger(__name__)


class DataClass(str, Enum):
    """Classification of data for retention policies"""

    EPISODIC_MEMORY = "episodic_memory"  # Layer: em
    LONG_TERM_MEMORY = "long_term_memory"  # Layer: ltm
    REFLECTIVE_MEMORY = "reflective_memory"  # Layer: rm
    SEMANTIC_NODES = "semantic_nodes"  # Knowledge graph nodes
    GRAPH_TRIPLES = "graph_triples"  # Knowledge graph relationships
    AUDIT_LOGS = "audit_logs"  # System audit logs
    COST_LOGS = "cost_logs"  # Cost tracking logs
    EMBEDDINGS = "embeddings"  # Vector embeddings


class DeletionReason(str, Enum):
    """Reason for data deletion (for audit trail)"""

    RETENTION_POLICY = "retention_policy"  # Expired per retention policy
    USER_REQUEST = "user_request"  # User requested deletion (GDPR Art. 17)
    TENANT_DELETION = "tenant_deletion"  # Tenant account deleted
    DATA_QUALITY = "data_quality"  # Low quality/corrupted data
    LEGAL_REQUIREMENT = "legal_requirement"  # Legal compliance requirement
    ADMIN_ACTION = "admin_action"  # Manual admin deletion


class RetentionPolicy(BaseModel):
    """Retention policy configuration"""

    data_class: DataClass
    retention_days: int = Field(
        ge=-1,
        description="Days to retain data (0 = never delete, -1 = delete immediately)",
    )
    soft_delete_grace_days: int = Field(
        default=30,
        ge=0,
        description="Days to keep soft-deleted data before hard delete",
    )
    exceptions: List[str] = Field(
        default_factory=list, description="Tags/IDs exempt from deletion"
    )


class DeletionAuditEntry(BaseModel):
    """Audit entry for deletion operation"""

    id: UUID
    tenant_id: str
    data_class: DataClass
    deletion_reason: DeletionReason
    deleted_count: int
    deleted_by: Optional[str] = None  # User/system that triggered deletion
    deletion_timestamp: datetime
    metadata: Dict = Field(default_factory=dict)


class RetentionService:
    """
    Service for managing data retention and GDPR-compliant deletion

    Handles:
    - Automatic cleanup based on retention policies
    - User-requested deletion (right to be forgotten)
    - Cascade deletion of related data
    - Soft delete with grace period
    - Audit trail for all deletions
    """

    # Default retention policies (days)
    DEFAULT_RETENTION_POLICIES = {
        DataClass.EPISODIC_MEMORY: 365,  # 1 year
        DataClass.LONG_TERM_MEMORY: -1,  # Never delete (permanent knowledge)
        DataClass.REFLECTIVE_MEMORY: -1,  # Never delete (insights)
        DataClass.SEMANTIC_NODES: -1,  # Never delete (knowledge graph)
        DataClass.GRAPH_TRIPLES: -1,  # Never delete (relationships)
        DataClass.AUDIT_LOGS: 2555,  # 7 years (legal requirement in many jurisdictions)
        DataClass.COST_LOGS: 1095,  # 3 years (financial records)
        DataClass.EMBEDDINGS: 365,  # 1 year (can be regenerated)
    }

    def __init__(self, db: asyncpg.Pool):
        self.db = db
        self.logger = logging.getLogger(__name__)

    async def get_tenant_retention_policies(
        self, tenant_id: str
    ) -> Dict[DataClass, RetentionPolicy]:
        """
        Get retention policies for a tenant

        Loads from tenant config or uses defaults
        """
        # Try to load from tenant_config table
        try:
            record = await self.db.fetchrow(
                """
                SELECT config FROM tenants WHERE id = $1
                """,
                UUID(tenant_id),
            )

            if record and record["config"]:
                tenant_config = record["config"]
                # Extract retention_days if present
                retention_days = tenant_config.get("memory_retention_days", 365)
            else:
                retention_days = 365  # Default

        except Exception as e:
            self.logger.warning(
                f"Failed to load tenant config for {tenant_id}: {e}, using defaults"
            )
            retention_days = 365

        # Build retention policies
        policies: Dict[DataClass, RetentionPolicy] = {}
        for data_class, default_days in self.DEFAULT_RETENTION_POLICIES.items():
            # Override episodic memory retention from tenant config
            if data_class == DataClass.EPISODIC_MEMORY:
                policies[data_class] = RetentionPolicy(
                    data_class=data_class, retention_days=retention_days
                )
            else:
                policies[data_class] = RetentionPolicy(
                    data_class=data_class, retention_days=default_days
                )

        return policies

    async def cleanup_expired_data(
        self, tenant_id: Optional[str] = None
    ) -> Dict[DataClass, int]:
        """
        Clean up expired data based on retention policies

        Args:
            tenant_id: Optional tenant to clean up. If None, processes all tenants.

        Returns:
            Dict mapping data class to count of records deleted
        """
        results: Dict[DataClass, int] = {}

        if tenant_id:
            tenants = [tenant_id]
        else:
            # Get all tenants
            tenant_records = await self.db.fetch(
                "SELECT DISTINCT tenant_id FROM memories WHERE tenant_id IS NOT NULL"
            )
            tenants = [r["tenant_id"] for r in tenant_records]

        self.logger.info(
            f"Starting retention cleanup for {len(tenants)} tenant(s)",
            extra={"tenant_count": len(tenants)},
        )

        for tenant_id in tenants:
            try:
                policies = await self.get_tenant_retention_policies(tenant_id)

                # Cleanup episodic memories
                if policies[DataClass.EPISODIC_MEMORY].retention_days > 0:
                    deleted = await self._cleanup_episodic_memories(
                        tenant_id, policies[DataClass.EPISODIC_MEMORY]
                    )
                    results[DataClass.EPISODIC_MEMORY] = (
                        results.get(DataClass.EPISODIC_MEMORY, 0) + deleted
                    )

                # Cleanup embeddings (if table exists)
                if policies[DataClass.EMBEDDINGS].retention_days > 0:
                    deleted = await self._cleanup_embeddings(
                        tenant_id, policies[DataClass.EMBEDDINGS]
                    )
                    results[DataClass.EMBEDDINGS] = (
                        results.get(DataClass.EMBEDDINGS, 0) + deleted
                    )

                # Cleanup cost logs
                if policies[DataClass.COST_LOGS].retention_days > 0:
                    deleted = await self._cleanup_cost_logs(
                        tenant_id, policies[DataClass.COST_LOGS]
                    )
                    results[DataClass.COST_LOGS] = (
                        results.get(DataClass.COST_LOGS, 0) + deleted
                    )

                self.logger.info(
                    f"Retention cleanup complete for tenant {tenant_id}",
                    extra={"tenant_id": tenant_id, "deleted": results},
                )

            except Exception as e:
                self.logger.error(
                    f"Retention cleanup failed for tenant {tenant_id}: {e}",
                    extra={"tenant_id": tenant_id, "error": str(e)},
                )
                # Continue with other tenants

        return results

    async def _cleanup_episodic_memories(
        self, tenant_id: str, policy: RetentionPolicy
    ) -> int:
        """Clean up expired episodic memories"""

        cutoff_date = utc_now() - timedelta(days=policy.retention_days)

        # Delete expired memories (respecting exceptions)
        result = await self.db.execute(
            """
            DELETE FROM memories
            WHERE tenant_id = $1
              AND layer = 'em'
              AND created_at < $2
              AND NOT EXISTS (
                  SELECT 1 FROM unnest($3::text[]) AS exception
                  WHERE exception = ANY(tags)
              )
            """,
            tenant_id,
            cutoff_date,
            policy.exceptions,
        )

        deleted_count = int(result.split()[-1]) if result else 0

        if deleted_count > 0:
            # Log audit entry
            await self._log_deletion_audit(
                tenant_id=tenant_id,
                data_class=DataClass.EPISODIC_MEMORY,
                deletion_reason=DeletionReason.RETENTION_POLICY,
                deleted_count=deleted_count,
                metadata={
                    "cutoff_date": cutoff_date.isoformat(),
                    "retention_days": policy.retention_days,
                },
            )

            self.logger.info(
                f"Deleted {deleted_count} episodic memories for tenant {tenant_id}",
                extra={
                    "tenant_id": tenant_id,
                    "deleted_count": deleted_count,
                    "cutoff_date": cutoff_date.isoformat(),
                },
            )

        return deleted_count

    async def _cleanup_embeddings(self, tenant_id: str, policy: RetentionPolicy) -> int:
        """Clean up old embeddings (orphaned or expired)"""

        cutoff_date = utc_now() - timedelta(days=policy.retention_days)

        try:
            # Delete orphaned embeddings (memories no longer exist)
            result = await self.db.execute(
                """
                DELETE FROM embeddings
                WHERE tenant_id = $1
                  AND created_at < $2
                  AND NOT EXISTS (
                      SELECT 1 FROM memories m WHERE m.id = embeddings.memory_id
                  )
                """,
                tenant_id,
                cutoff_date,
            )

            deleted_count = int(result.split()[-1]) if result else 0

            if deleted_count > 0:
                await self._log_deletion_audit(
                    tenant_id=tenant_id,
                    data_class=DataClass.EMBEDDINGS,
                    deletion_reason=DeletionReason.RETENTION_POLICY,
                    deleted_count=deleted_count,
                    metadata={"cutoff_date": cutoff_date.isoformat()},
                )

            return deleted_count

        except Exception as e:
            # Table may not exist
            self.logger.debug(f"Embeddings cleanup skipped: {e}")
            return 0

    async def _cleanup_cost_logs(self, tenant_id: str, policy: RetentionPolicy) -> int:
        """Clean up old cost logs"""

        cutoff_date = utc_now() - timedelta(days=policy.retention_days)

        try:
            result = await self.db.execute(
                """
                DELETE FROM cost_logs
                WHERE tenant_id = $1 AND timestamp < $2
                """,
                tenant_id,
                cutoff_date,
            )

            deleted_count = int(result.split()[-1]) if result else 0

            if deleted_count > 0:
                await self._log_deletion_audit(
                    tenant_id=tenant_id,
                    data_class=DataClass.COST_LOGS,
                    deletion_reason=DeletionReason.RETENTION_POLICY,
                    deleted_count=deleted_count,
                    metadata={"cutoff_date": cutoff_date.isoformat()},
                )

            return deleted_count

        except Exception as e:
            self.logger.debug(f"Cost logs cleanup skipped: {e}")
            return 0

    async def _log_deletion_audit(
        self,
        tenant_id: str,
        data_class: DataClass,
        deletion_reason: DeletionReason,
        deleted_count: int,
        deleted_by: Optional[str] = None,
        metadata: Optional[Dict] = None,
    ):
        """Log deletion operation to audit trail"""

        try:
            await self.db.execute(
                """
                INSERT INTO deletion_audit_log (
                    id, tenant_id, data_class, deletion_reason,
                    deleted_count, deleted_by, deletion_timestamp, metadata
                )
                VALUES (gen_random_uuid(), $1, $2, $3, $4, $5, $6, $7)
                """,
                tenant_id,
                data_class.value,
                deletion_reason.value,
                deleted_count,
                deleted_by or "system",
                utc_now(),
                metadata or {},
            )
        except Exception as e:
            # If audit log table doesn't exist, log to application logs
            self.logger.warning(
                f"Failed to write deletion audit log: {e}. Logging to app logs instead.",
                extra={
                    "tenant_id": tenant_id,
                    "data_class": data_class.value,
                    "deletion_reason": deletion_reason.value,
                    "deleted_count": deleted_count,
                    "deleted_by": deleted_by,
                    "metadata": metadata,
                },
            )

    async def delete_user_data(
        self, tenant_id: str, user_identifier: str, deleted_by: str
    ) -> Dict[str, int]:
        """
        GDPR Article 17: Right to erasure ("right to be forgotten")

        Delete all data associated with a user across all data classes.
        This is a cascade delete that removes:
        - All memories
        - All semantic nodes
        - All graph triples
        - All embeddings
        - All reflections
        - All cost logs (pseudonymized user data only)

        Args:
            tenant_id: Tenant ID
            user_identifier: User email, ID, or other identifier
            deleted_by: Who requested the deletion (for audit)

        Returns:
            Dict mapping data class to count of records deleted
        """
        results = {}

        self.logger.info(
            f"Starting GDPR deletion for user {user_identifier} in tenant {tenant_id}",
            extra={
                "tenant_id": tenant_id,
                "user_identifier": user_identifier,
                "deleted_by": deleted_by,
            },
        )

        async with self.db.acquire() as conn:
            async with conn.transaction():
                # Delete memories
                result = await conn.execute(
                    """
                    DELETE FROM memories
                    WHERE tenant_id = $1
                      AND (
                          source = $2
                          OR source_owner = $2
                          OR content ILIKE '%' || $2 || '%'
                      )
                    """,
                    tenant_id,
                    user_identifier,
                )
                results["memories"] = int(result.split()[-1]) if result else 0

                # Delete semantic nodes
                try:
                    result = await conn.execute(
                        """
                        DELETE FROM semantic_nodes
                        WHERE tenant_id = $1 AND source_owner = $2
                        """,
                        tenant_id,
                        user_identifier,
                    )
                    results["semantic_nodes"] = int(result.split()[-1]) if result else 0
                except Exception:
                    pass

                # Delete reflections
                try:
                    result = await conn.execute(
                        """
                        DELETE FROM reflections
                        WHERE tenant_id = $1
                          AND (
                              created_by = $2
                              OR content ILIKE '%' || $2 || '%'
                          )
                        """,
                        tenant_id,
                        user_identifier,
                    )
                    results["reflections"] = int(result.split()[-1]) if result else 0
                except Exception:
                    pass

                # Pseudonymize cost logs (don't delete financial records, but anonymize)
                try:
                    result = await conn.execute(
                        """
                        UPDATE cost_logs
                        SET metadata = jsonb_set(
                            metadata,
                            '{user_anonymized}',
                            'true'::jsonb
                        ),
                        user_id = 'ANONYMIZED'
                        WHERE tenant_id = $1 AND user_id = $2
                        """,
                        tenant_id,
                        user_identifier,
                    )
                    results["cost_logs_anonymized"] = (
                        int(result.split()[-1]) if result else 0
                    )
                except Exception:
                    pass

        # Log audit entry
        await self._log_deletion_audit(
            tenant_id=tenant_id,
            data_class=DataClass.EPISODIC_MEMORY,  # Representative
            deletion_reason=DeletionReason.USER_REQUEST,
            deleted_count=sum(results.values()),
            deleted_by=deleted_by,
            metadata={
                "user_identifier": user_identifier,
                "deletion_breakdown": results,
            },
        )

        self.logger.info(
            f"GDPR deletion complete for user {user_identifier}",
            extra={"tenant_id": tenant_id, "results": results},
        )

        return results

    async def get_deletion_audit_log(
        self,
        tenant_id: str,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
        limit: int = 100,
    ) -> List[Dict]:
        """
        Get deletion audit log for compliance reporting

        Returns list of deletion operations with full audit trail
        """
        try:
            query = """
                SELECT *
                FROM deletion_audit_log
                WHERE tenant_id = $1
            """
            params: List[Any] = [tenant_id]
            param_idx = 2

            if start_date:
                query += f" AND deletion_timestamp >= ${param_idx}"
                params.append(start_date)
                param_idx += 1

            if end_date:
                query += f" AND deletion_timestamp <= ${param_idx}"
                params.append(end_date)
                param_idx += 1

            query += f" ORDER BY deletion_timestamp DESC LIMIT ${param_idx}"
            params.append(limit)

            records = await self.db.fetch(query, *params)

            return [dict(record) for record in records]

        except Exception as e:
            self.logger.warning(
                f"Deletion audit log query failed: {e}. Table may not exist."
            )
            return []
