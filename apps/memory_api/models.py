from datetime import datetime
from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field, field_validator

# --- Core Memory Models ---


class MemoryLayer(str, Enum):
    """
    Enum for memory layers, representing different levels of processing and retention.

    Logicalwarstwa przetwarzania (STM/LTM/episodic/reflective).
    See: docs/MEMORY_MODEL.md for complete layer mapping.

    - stm/working: Short-term memory (Layer 1/2), volatile and immediate
    - ltm/semantic: Long-term memory (Layer 3), consolidated and durable
    - em/episodic: Episodic memory (Layer 2/3), time-sequenced events
    - rm/reflective: Reflective memory (Layer 4), synthesized meta-learning
    - sensory: Sensory buffer (Layer 0), immediate perception
    """

    # Short codes (legacy)
    stm = "stm"
    ltm = "ltm"
    rm = "rm"
    em = "em"

    # Full names (new standard from RAE-core)
    working = "working"
    semantic = "semantic"
    reflective = "reflective"
    episodic = "episodic"
    sensory = "sensory"


class SourceTrustLevel(str, Enum):
    """
    Trust level for knowledge sources - ISO/IEC 42001 compliance

    Used to assess reliability and quality of information sources:
    - high: Verified, authoritative sources (official docs, verified experts)
    - medium: Generally reliable (team knowledge, tested code)
    - low: Unverified or potentially outdated (user input, external sources)
    - unverified: New sources pending verification
    """

    high = "high"
    medium = "medium"
    low = "low"
    unverified = "unverified"


class OperationRiskLevel(str, Enum):
    """
    Risk level for AI operations - ISO/IEC 42001 Section 9 (Human Oversight)

    Determines whether human approval is required before execution:
    - critical: Requires mandatory human approval (financial, legal, safety)
    - high: Requires human review before execution
    - medium: Can proceed with logging and post-hoc review
    - low: Automatic execution allowed
    - none: No special oversight required
    """

    critical = "critical"
    high = "high"
    medium = "medium"
    low = "low"
    none = "none"


class MemoryRecord(BaseModel):
    """
    The standard, unified format for a memory record.

    Note on memory classification:
    - layer: Processing stage (stm/ltm/em/rm) - determines retention strategy
    - memory_type: Functional type (sensory/episodic/semantic/reflection/strategy)

    ISO/IEC 42001 compliance fields:
    - source_owner: Person/system responsible for this knowledge source
    - trust_level: Reliability classification (high/medium/low/unverified)
    - last_verified_at: Timestamp of last verification
    - verification_notes: Notes from verification process

    See: docs/MEMORY_MODEL.md for detailed mapping
    """

    id: str
    tenant_id: Optional[str] = None  # Added for multi-tenancy support
    content: str
    source: Optional[str] = None
    importance: float = 0.5
    layer: MemoryLayer = MemoryLayer.semantic  # See MEMORY_MODEL.md for layer mapping
    tags: Optional[List[str]] = None
    timestamp: datetime = Field(default_factory=datetime.now)
    last_accessed_at: Optional[datetime] = None
    usage_count: int = 0
    project: Optional[str] = None

    # ISO/IEC 42001 - Source Trust & Provenance
    source_owner: Optional[str] = Field(
        None, max_length=255, description="Owner/responsible party for this source"
    )
    trust_level: SourceTrustLevel = Field(
        SourceTrustLevel.unverified, description="Trust level of the source"
    )
    last_verified_at: Optional[datetime] = Field(
        None, description="Timestamp of last verification"
    )
    verification_notes: Optional[str] = Field(
        None, max_length=1024, description="Notes from verification process"
    )

    # Phase 2: Telemetry & Sync Fields
    provenance: Optional[Dict[str, Any]] = Field(
        default_factory=dict,
        description="Origin and lineage of the memory (e.g., source file, url, author)",
    )
    sync_metadata: Optional[Dict[str, Any]] = Field(
        default_factory=dict,
        description="Synchronization state metadata (e.g., vector_clock, version)",
    )


class ScoredMemoryRecord(MemoryRecord):
    """
    A memory record augmented with a relevance score, typically from a query.
    """

    score: float


# --- API Request/Response Models ---


class StoreMemoryRequest(BaseModel):
    """
    Request model for storing a new memory.
    The 'id' and other metadata are generated by the service.

    ISO/IEC 42001 compliance:
    Supports source trust scoring and provenance tracking
    """

    content: str = Field(min_length=1, max_length=65536)
    source: Optional[str] = Field(None, max_length=255)
    importance: Optional[float] = Field(default=None, ge=0.0, le=1.0)
    layer: Optional[MemoryLayer] = None
    tags: Optional[List[str]] = None
    timestamp: Optional[datetime] = None
    project: Optional[str] = Field(None, max_length=255)

    # Phase 1: Canonical fields for DB Refactor
    session_id: Optional[str] = Field(
        None, description="Session identifier for conversation grouping"
    )
    memory_type: Optional[str] = Field(
        None, description="Functional type (text, code, image, etc.)"
    )
    ttl: Optional[int] = Field(
        None, gt=0, description="Time-to-live in seconds"
    )
    strength: Optional[float] = Field(
        default=1.0, ge=0.0, le=1.0, description="Memory strength (for decay)"
    )

    # ISO/IEC 42001 - Source Trust & Provenance
    source_owner: Optional[str] = Field(
        None, max_length=255, description="Owner/responsible party for this source"
    )
    trust_level: Optional[SourceTrustLevel] = Field(
        None, description="Trust level of the source (high/medium/low/unverified)"
    )
    verification_notes: Optional[str] = Field(
        None, max_length=1024, description="Notes about source verification"
    )

    @field_validator("layer", mode="before")
    @classmethod
    def normalize_layer(cls, v: Any) -> Any:
        """Normalize legacy short layer codes to full standard names."""
        mapping = {
            "em": "episodic",
            "stm": "working",
            "wm": "working",
            "sm": "semantic",
            "ltm": "ltm",  # Fix: Keep ltm distinct from semantic
            "rm": "reflective",
        }
        if isinstance(v, str) and v.lower() in mapping:
            return mapping[v.lower()]
        return v

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "content": "User prefers dark mode UI",
                    "source": "user_interaction",
                    "importance": 0.8,
                    "layer": "em",
                    "tags": ["preferences", "ui"],
                    "project": "my-app",
                    "source_owner": "john.doe@company.com",
                    "trust_level": "high",
                    "verification_notes": "Verified from user profile settings",
                }
            ]
        }
    }


class StoreMemoryResponse(BaseModel):
    id: str
    message: str = "Memory stored successfully."


class QueryMemoryRequest(BaseModel):
    query_text: str = Field(min_length=1, max_length=1024)
    k: int = Field(default=10, gt=0, le=100)
    filters: Optional[Dict[str, Any]] = None
    # Hybrid search parameters
    use_graph: bool = Field(
        default=False, description="Enable hybrid search with graph traversal"
    )
    graph_depth: int = Field(
        default=2, ge=1, le=5, description="Maximum graph traversal depth"
    )
    project: Optional[str] = Field(
        default=None, max_length=255, description="Project identifier for graph search"
    )

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "query_text": "What are the user's UI preferences?",
                    "k": 5,
                    "filters": {"tags": ["preferences"]},
                    "use_graph": False,
                },
                {
                    "query_text": "Find related concepts about authentication",
                    "k": 10,
                    "use_graph": True,
                    "graph_depth": 3,
                    "project": "my-app",
                },
            ]
        }
    }


class QueryMemoryResponse(BaseModel):
    results: List[ScoredMemoryRecord] = []
    # Optional hybrid search context
    synthesized_context: Optional[str] = Field(
        default=None, description="Synthesized context from hybrid search"
    )
    graph_statistics: Optional[Dict[str, Any]] = Field(
        default=None, description="Graph search statistics"
    )


class DeleteMemoryRequest(BaseModel):
    memory_id: str


class DeleteMemoryResponse(BaseModel):
    message: str


class RebuildReflectionsRequest(BaseModel):
    project: str = Field(min_length=1, max_length=255)
    tenant_id: str = Field(min_length=1, max_length=255)


# --- Agent-related Models ---


class AgentExecuteRequest(BaseModel):
    tenant_id: str = Field(min_length=1, max_length=255)
    project: str = Field(min_length=1, max_length=255)
    prompt: str = Field(min_length=1, max_length=8192)
    tools_allowed: Optional[List[str]] = None
    budget_tokens: int = Field(default=20000, gt=0, le=100000)

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "tenant_id": "my-tenant",
                    "project": "my-project",
                    "prompt": "Summarize what the user learned about Python today",
                    "budget_tokens": 15000,
                }
            ]
        }
    }


class CostInfo(BaseModel):
    input_tokens: int = 0
    output_tokens: int = 0
    total_estimate: float = 0.0


class AgentExecuteResponse(BaseModel):
    answer: str
    used_memories: QueryMemoryResponse
    cost: CostInfo
