from typing import List, Optional, Any, Dict
from pydantic import BaseModel, Field, constr
from enum import Enum
from datetime import datetime

# --- Core Memory Models ---

class MemoryLayer(str, Enum):
    """
    Enum for memory layers, representing different levels of processing and retention.
    - stm: Short-term memory, volatile and immediate.
    - ltm: Long-term memory, consolidated and durable.
    - rm: Reflective memory, synthesized from other memories.
    """
    stm = "stm"
    ltm = "ltm"
    rm = "rm"
    em = "em" # Added from previous task, should be here

class MemoryRecord(BaseModel):
    """
    The standard, unified format for a memory record.
    """
    id: str
    content: str
    source: Optional[str] = None
    importance: float = 0.5
    layer: MemoryLayer = MemoryLayer.ltm
    tags: Optional[List[str]] = None
    timestamp: datetime = Field(default_factory=datetime.now)
    last_accessed_at: Optional[datetime] = None
    usage_count: int = 0
    project: Optional[str] = None # Added from previous task, should be here

class ScoredMemoryRecord(MemoryRecord):
    """
    A memory record augmented with a relevance score, typically from a query.
    """
    score: float

# --- API Request/Response Models ---

class StoreMemoryRequest(BaseModel):
    """
    Request model for storing a new memory.
    The 'id' and other metadata are generated by the service.
    """
    content: constr(min_length=1, max_length=8192)
    source: Optional[constr(max_length=255)] = None
    importance: Optional[float] = Field(default=None, ge=0.0, le=1.0)
    layer: Optional[MemoryLayer] = None
    tags: Optional[List[str]] = None
    timestamp: Optional[datetime] = None
    project: Optional[constr(max_length=255)] = None

class StoreMemoryResponse(BaseModel):
    id: str
    message: str = "Memory stored successfully."

class QueryMemoryRequest(BaseModel):
    query_text: constr(min_length=1, max_length=1024)
    k: int = Field(default=10, gt=0, le=100)
    filters: Optional[Dict[str, Any]] = None
    # Hybrid search parameters
    use_graph: bool = Field(default=False, description="Enable hybrid search with graph traversal")
    graph_depth: int = Field(default=2, ge=1, le=5, description="Maximum graph traversal depth")
    project: Optional[constr(max_length=255)] = Field(default=None, description="Project identifier for graph search")

class QueryMemoryResponse(BaseModel):
    results: List[ScoredMemoryRecord] = []
    # Optional hybrid search context
    synthesized_context: Optional[str] = Field(default=None, description="Synthesized context from hybrid search")
    graph_statistics: Optional[Dict[str, Any]] = Field(default=None, description="Graph search statistics")

class DeleteMemoryRequest(BaseModel):
    memory_id: str

class DeleteMemoryResponse(BaseModel):
    message: str

class RebuildReflectionsRequest(BaseModel):
    project: constr(min_length=1, max_length=255)
    tenant_id: constr(min_length=1, max_length=255)

# --- Agent-related Models ---

class AgentExecuteRequest(BaseModel):
    tenant_id: constr(min_length=1, max_length=255)
    project: constr(min_length=1, max_length=255)
    prompt: constr(min_length=1, max_length=8192)
    tools_allowed: Optional[List[str]] = None
    budget_tokens: int = Field(default=20000, gt=0, le=100000)

class CostInfo(BaseModel):
    input_tokens: int = 0
    output_tokens: int = 0
    total_estimate: float = 0.0

class AgentExecuteResponse(BaseModel):
    answer: str
    used_memories: QueryMemoryResponse
    cost: CostInfo